name: Federal Register Data Update

on:
  schedule:
    - cron: "0 15 * * *" # Runs at 15:00 UTC (8 AM PT) every day
  workflow_dispatch: # Allows manual triggering

permissions:
  contents: write
  pull-requests: write
  issues: write

jobs:
  scrape:
    runs-on: ubuntu-latest
    steps:
      - name: ðŸ›’ Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: ðŸ Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.x"

      - name: ðŸ“¦ Install dependencies
        run: pip install -r requirements.txt

      - name: ðŸª  Run scraper
        run: python scripts/scrape.py

      - name: ðŸ“… Get current date
        id: date
        run: echo "date=$(date +'%Y-%m-%d')" >> $GITHUB_OUTPUT

      - name: ðŸ¤” Check for changes
        id: changes
        run: |
          if [[ -n "$(git status --porcelain src/data.json)" ]]; then
            echo "changed=1" >> $GITHUB_OUTPUT
            echo "Changes detected in src/data.json"
          else
            echo "changed=0" >> $GITHUB_OUTPUT
            echo "No changes detected in src/data.json"
          fi

      - name: ðŸ”„ Create Pull Request
        if: steps.changes.outputs.changed == 1
        uses: peter-evans/create-pull-request@v7
        with:
          token: ${{ secrets.GITHUB_TOKEN }}
          committer: "github-actions[bot] <github-actions[bot]@users.noreply.github.com>"
          branch: data-update-${{ steps.date.outputs.date }}
          commit-message: Update data for ${{ steps.date.outputs.date }}
          title: "chore: Federal Register data update ${{ steps.date.outputs.date }}"
          body: |
            Automated data update from Federal Registry scraper

            - Updated src/data.json
